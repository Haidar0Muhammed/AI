{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426dd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from numpy import reshape,asarray,shape\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score, recall_score, classification_report\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LinearRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "tweet = pd.read_csv('D:\\\\Projects\\\\AI\\\\Twitter Hate Speech\\\\TwitterHate.csv')\n",
    "tweet.drop('id',axis=1,inplace=True)\n",
    "df = tweet.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b84b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].str.lower()\n",
    "\n",
    "df['tweet'].replace(r'@\\w+','',regex=True,inplace=True)\n",
    "\n",
    "df['tweet'].replace(r'http\\S+','',regex=True,inplace=True)\n",
    "\n",
    "def rem_hash_punct(text):\n",
    "    text = ''.join(text)\n",
    "    clean_text = re.sub(r\"#\",'',text)\n",
    "    clean_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return clean_text\n",
    "\n",
    "def rem_digits(text):\n",
    "    no_digits = []\n",
    "    for word in text:\n",
    "        no_digits.append(re.sub(r'\\d','',word))\n",
    "    return ''.join(no_digits)\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(rem_hash_punct)\n",
    "df['tweet'] = df['tweet'].apply(rem_digits)\n",
    "\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=True)\n",
    "df['tweet'] = df['tweet'].apply(tokenizer.tokenize)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    clean_text = [word for word in text if not word in stop_words]\n",
    "    return clean_text  \n",
    "\n",
    "df['tweet'] = df['tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077d40ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_Lemm(tokens):\n",
    "    for token in tokens:\n",
    "        token = wordnet_lemmatizer.lemmatize(token, pos=\"v\")\n",
    "    return tokens\n",
    "        \n",
    "df['tweet'] = df['tweet'].apply(remove_Lemm)\n",
    "\n",
    "def rem_nonalpha(text):\n",
    "    text = [word for word in text if word.isalpha()]\n",
    "    return text\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(rem_nonalpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "881dd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):\n",
    "    str1 = \"\"\n",
    "\n",
    "    for ele in s:\n",
    "        str1 += ele\n",
    "        str1 += \" \"\n",
    "\n",
    "    return str1\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(listToString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a99b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_Normal = df[df['label'] == 0]['tweet'].count()\n",
    "Hate = df[df['label'] == 1]\n",
    "Normal = df[df['label'] == 0]\n",
    "Hate_oversample = Hate.sample(cnt_Normal, replace=True)\n",
    "oversampled = pd.concat([Normal, Hate_oversample], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302b57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = oversampled['tweet']\n",
    "y = oversampled[\"label\"]\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "transformer  = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
    "\n",
    "X_counts = count_vect.fit_transform(X)\n",
    "X_Vec = transformer.fit_transform(X_counts)\n",
    "\n",
    "X_Vec = pd.DataFrame.sparse.from_spmatrix(X_Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a18779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    N = tn + fp + fn + tp\n",
    "    C = tn+tp\n",
    "\n",
    "    E = abs(C-N)/N\n",
    "    W = 0.5 * log((1-E)/E)\n",
    "    return(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f28a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Vec,y, test_size=0.33, random_state=44, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2fe2596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "0.9988951386098834\n",
      "============================================================\n",
      "Random Forest:\n",
      "0.8477551225391724\n",
      "============================================================\n",
      "Naive Bayes:\n",
      "0.9684612294094014\n",
      "============================================================\n",
      "Hard Voting:\n",
      "0.9770490156689433\n",
      "============================================================\n",
      "Soft Voting:\n",
      "0.9804138208115709\n"
     ]
    }
   ],
   "source": [
    "W = []\n",
    "y_predict = []\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "Linear_Regression = LinearRegression()\n",
    "Linear_Regression.fit(X_train,y_train)\n",
    "pre = Linear_Regression.predict(X_train)\n",
    "\n",
    "y1_predict = []\n",
    "for i in pre:\n",
    "    if i>0.5:\n",
    "        y1_predict.append(1)\n",
    "    else:\n",
    "        y1_predict.append(0)\n",
    "\n",
    "print(accuracy_score(y_train,y1_predict))\n",
    "\n",
    "W.append(Weight(y_train,y1_predict))\n",
    "y_predict.append(y1_predict)\n",
    "\n",
    "\n",
    "print(\"============================================================\")\n",
    "print(\"Random Forest:\")\n",
    "Random_Forest = RandomForestClassifier(n_estimators=500,max_depth=10,n_jobs=1)\n",
    "Random_Forest.fit(X_train,y_train)\n",
    "print(Random_Forest.score(X_train,y_train))\n",
    "\n",
    "y2_predict = Random_Forest.predict(X_train)\n",
    "W.append(Weight(y_train,y2_predict))\n",
    "y_predict.append(y2_predict)\n",
    "\n",
    "\n",
    "print(\"============================================================\")\n",
    "print(\"Naive Bayes:\")\n",
    "Naive_Bayes = MultinomialNB()\n",
    "Naive_Bayes.fit(X_train,y_train)\n",
    "print(Naive_Bayes.score(X_train,y_train))\n",
    "\n",
    "y3_predict = Naive_Bayes.predict(X_train)\n",
    "W.append(Weight(y_train,y3_predict))\n",
    "y_predict.append(y3_predict)\n",
    "\n",
    "print(\"============================================================\")\n",
    "print(\"Hard Voting:\")\n",
    "KNeighbors_Hard = KNeighborsClassifier(n_neighbors=10)\n",
    "Decision_Tree_Hard = DecisionTreeClassifier(criterion = 'gini',max_depth=10,random_state = 33)\n",
    "SGD_Hard = SGDClassifier(loss='log')\n",
    "Hard_Voting = VotingClassifier(estimators=[('KN_H', KNeighbors_Hard),('DT_H', Decision_Tree_Hard),\n",
    "                                           ('SGD_H',SGD_Hard)],voting='hard')\n",
    "\n",
    "Hard_Voting.fit(X_train,y_train)\n",
    "print(Hard_Voting.score(X_train,y_train))\n",
    "\n",
    "y4_predict = Hard_Voting.predict(X_train)\n",
    "W.append(Weight(y_train,y4_predict))\n",
    "y_predict.append(y4_predict)\n",
    "\n",
    "\n",
    "print(\"============================================================\")\n",
    "print(\"Soft Voting:\")\n",
    "KNeighbors_Soft = KNeighborsClassifier(n_neighbors=10)\n",
    "Decision_Tree_Soft = DecisionTreeClassifier(criterion = 'gini',max_depth=10,random_state = 33)\n",
    "SGD_Soft = SGDClassifier(loss='log')\n",
    "Soft_Voting = VotingClassifier(estimators=[('KN_S', KNeighbors_Soft),('DT_S', Decision_Tree_Soft),\n",
    "                                           ('SGD_S',SGD_Soft)],voting='soft')\n",
    "Soft_Voting.fit(X_train,y_train)\n",
    "print(Soft_Voting.score(X_train,y_train))\n",
    "\n",
    "y5_predict = Soft_Voting.predict(X_train)\n",
    "W.append(Weight(y_train,y5_predict))\n",
    "y_predict.append(y5_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "293145bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta = []\n",
    "\n",
    "y_predict = asarray(y_predict)\n",
    "y_predict = y_predict.T\n",
    "\n",
    "for XX in y_predict:\n",
    "    tt = []\n",
    "    for k in range(0,5):\n",
    "        tt.append(XX[k]*W[k])\n",
    "    \n",
    "    X_meta.append(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c262bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=500, random_state=33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Meta = MLPClassifier(hidden_layer_sizes=(1024,128,64), activation='relu',solver='adam', max_iter=200)\n",
    "Meta = RandomForestClassifier(n_estimators=500, criterion = 'gini',max_depth=10,random_state = 33)\n",
    "Meta.fit(X_meta,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2edb75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_Regression\n",
      "accuracy:  0.9415783034257749\n",
      "precision:  0.8970132944818794\n",
      "f1:  0.9450306983883345\n",
      "recall:  0.9984796270018245\n",
      "confusion_matrix:  [[8619 1131]\n",
      " [  15 9851]]\n",
      "============================================================\n",
      "Random_Forest\n",
      "accuracy:  0.8470636215334421\n",
      "precision:  0.9475880052151239\n",
      "f1:  0.8289233576642336\n",
      "recall:  0.7366713967159944\n",
      "confusion_matrix:  [[9348  402]\n",
      " [2598 7268]]\n",
      "============================================================\n",
      "Naive_Bayes\n",
      "accuracy:  0.9515191680261011\n",
      "precision:  0.9225519006540904\n",
      "f1:  0.9534166054371784\n",
      "recall:  0.9864180012162984\n",
      "confusion_matrix:  [[8933  817]\n",
      " [ 134 9732]]\n",
      "============================================================\n",
      "Hard_Voting\n",
      "accuracy:  0.9676794453507341\n",
      "precision:  0.9765641131530043\n",
      "f1:  0.9675736497545008\n",
      "recall:  0.9587472126495034\n",
      "confusion_matrix:  [[9523  227]\n",
      " [ 407 9459]]\n",
      "============================================================\n",
      "Soft_Voting\n",
      "accuracy:  0.970942088091354\n",
      "precision:  0.9549725920125294\n",
      "f1:  0.9716163728712279\n",
      "recall:  0.9888505980133793\n",
      "confusion_matrix:  [[9290  460]\n",
      " [ 110 9756]]\n"
     ]
    }
   ],
   "source": [
    "def SWE_Model():\n",
    "    yy_predict = []\n",
    "    \n",
    "    print(\"Linear_Regression\")\n",
    "    pre = Linear_Regression.predict(X_test)\n",
    "    yy1_predict = []\n",
    "    for i in pre:\n",
    "        if i>0.5:\n",
    "            yy1_predict.append(1)\n",
    "        else:\n",
    "            yy1_predict.append(0)\n",
    "    yy_predict.append(yy1_predict)\n",
    "    \n",
    "    print(\"accuracy: \",accuracy_score(y_test,yy1_predict))\n",
    "    print(\"precision: \",precision_score(y_test,yy1_predict))\n",
    "    print(\"f1: \",f1_score(y_test,yy1_predict))\n",
    "    print(\"recall: \",recall_score(y_test,yy1_predict))\n",
    "    print(\"confusion_matrix: \",confusion_matrix(y_test,yy1_predict))\n",
    "    print(\"============================================================\")\n",
    "    \n",
    "    \n",
    "    print(\"Random_Forest\")\n",
    "    yy2_predict = Random_Forest.predict(X_test)\n",
    "    yy_predict.append(yy2_predict)\n",
    "    \n",
    "    print(\"accuracy: \",accuracy_score(y_test,yy2_predict))\n",
    "    print(\"precision: \",precision_score(y_test,yy2_predict))\n",
    "    print(\"f1: \",f1_score(y_test,yy2_predict))\n",
    "    print(\"recall: \",recall_score(y_test,yy2_predict))\n",
    "    print(\"confusion_matrix: \",confusion_matrix(y_test,yy2_predict))\n",
    "    print(\"============================================================\")\n",
    "    \n",
    "    \n",
    "    print(\"Naive_Bayes\")\n",
    "    yy3_predict = Naive_Bayes.predict(X_test)\n",
    "    yy_predict.append(yy3_predict)\n",
    "    \n",
    "    print(\"accuracy: \",accuracy_score(y_test,yy3_predict))\n",
    "    print(\"precision: \",precision_score(y_test,yy3_predict))\n",
    "    print(\"f1: \",f1_score(y_test,yy3_predict))\n",
    "    print(\"recall: \",recall_score(y_test,yy3_predict))\n",
    "    print(\"confusion_matrix: \",confusion_matrix(y_test,yy3_predict))\n",
    "    print(\"============================================================\")\n",
    "    \n",
    "    \n",
    "    print(\"Hard_Voting\")\n",
    "    yy4_predict = Hard_Voting.predict(X_test)\n",
    "    yy_predict.append(yy4_predict)\n",
    "    \n",
    "    print(\"accuracy: \",accuracy_score(y_test,yy4_predict))\n",
    "    print(\"precision: \",precision_score(y_test,yy4_predict))\n",
    "    print(\"f1: \",f1_score(y_test,yy4_predict))\n",
    "    print(\"recall: \",recall_score(y_test,yy4_predict))\n",
    "    print(\"confusion_matrix: \",confusion_matrix(y_test,yy4_predict))\n",
    "    print(\"============================================================\")\n",
    "    \n",
    "    \n",
    "    print(\"Soft_Voting\")\n",
    "    yy5_predict = Soft_Voting.predict(X_test)\n",
    "    yy_predict.append(yy5_predict)\n",
    "    \n",
    "    print(\"accuracy: \",accuracy_score(y_test,yy5_predict))\n",
    "    print(\"precision: \",precision_score(y_test,yy5_predict))\n",
    "    print(\"f1: \",f1_score(y_test,yy5_predict))\n",
    "    print(\"recall: \",recall_score(y_test,yy5_predict))\n",
    "    print(\"confusion_matrix: \",confusion_matrix(y_test,yy5_predict))\n",
    "\n",
    "    \n",
    "    XX_meta = []\n",
    "\n",
    "    yy_predict = asarray(yy_predict)\n",
    "    yy_predict = yy_predict.T\n",
    "\n",
    "    for XX in yy_predict:\n",
    "        tt = []\n",
    "        for k in range(0,5):\n",
    "            tt.append(XX[k]*W[k])\n",
    "\n",
    "        XX_meta.append(tt)\n",
    "\n",
    "    return(Meta.predict(XX_meta))\n",
    "\n",
    "pred_arr = SWE_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63634748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9415783034257749\n",
      "precision:  0.8970132944818794\n",
      "f1:  0.9450306983883345\n",
      "recall:  0.9984796270018245\n",
      "confusion_matrix:  [[8619 1131]\n",
      " [  15 9851]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \",accuracy_score(y_test,pred_arr))\n",
    "print(\"precision: \",precision_score(y_test,pred_arr))\n",
    "print(\"f1: \",f1_score(y_test,pred_arr))\n",
    "print(\"recall: \",recall_score(y_test,pred_arr))\n",
    "print(\"confusion_matrix: \",confusion_matrix(y_test,pred_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "426e7cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42344</th>\n",
       "      <th>42345</th>\n",
       "      <th>42346</th>\n",
       "      <th>42347</th>\n",
       "      <th>42348</th>\n",
       "      <th>42349</th>\n",
       "      <th>42350</th>\n",
       "      <th>42351</th>\n",
       "      <th>42352</th>\n",
       "      <th>42353</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16970</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52063</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37745</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43063</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40808</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27877</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19616 rows × 42354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9      \\\n",
       "43978    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "16970    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "52063    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "40112    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "37745    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "10305    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "19014    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "43063    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "40808    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "27877    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       ...  42344  42345  42346  42347  42348  42349  42350  42351  42352  \\\n",
       "43978  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "16970  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "52063  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "40112  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "37745  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "10305  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "19014  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "43063  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "40808  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "27877  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       42353  \n",
       "43978    0.0  \n",
       "16970    0.0  \n",
       "52063    0.0  \n",
       "40112    0.0  \n",
       "37745    0.0  \n",
       "...      ...  \n",
       "10305    0.0  \n",
       "19014    0.0  \n",
       "43063    0.0  \n",
       "40808    0.0  \n",
       "27877    0.0  \n",
       "\n",
       "[19616 rows x 42354 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb21058e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19616, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Soft_Voting.transform(X_test).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c1bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23b9eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<19616x33384 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 106915959 stored elements in Compressed Sparse Row format>, array([    0,    59,   132,   191,   224,   293,   364,   417,   486,\n",
      "         561,   612,   709,   782,   849,   910,   983,  1084,  1135,\n",
      "        1208,  1297,  1370,  1433,  1510,  1581,  1656,  1723,  1816,\n",
      "        1885,  1966,  2053,  2136,  2219,  2294,  2353,  2422,  2483,\n",
      "        2548,  2615,  2646,  2743,  2818,  2889,  2952,  2999,  3056,\n",
      "        3109,  3158,  3209,  3286,  3323,  3358,  3415,  3490,  3581,\n",
      "        3648,  3711,  3782,  3839,  3892,  3957,  4010,  4075,  4140,\n",
      "        4199,  4264,  4335,  4380,  4429,  4478,  4541,  4634,  4705,\n",
      "        4784,  4857,  4942,  5025,  5074,  5125,  5212,  5291,  5370,\n",
      "        5473,  5512,  5555,  5632,  5685,  5734,  5815,  5888,  5943,\n",
      "        6018,  6079,  6148,  6255,  6302,  6383,  6480,  6541,  6618,\n",
      "        6681,  6754,  6849,  6930,  6995,  7066,  7115,  7186,  7251,\n",
      "        7344,  7413,  7478,  7559,  7612,  7693,  7766,  7839,  7918,\n",
      "        7969,  8014,  8101,  8172,  8249,  8310,  8371,  8420,  8479,\n",
      "        8528,  8621,  8668,  8721,  8788,  8811,  8882,  8955,  9012,\n",
      "        9093,  9182,  9261,  9310,  9385,  9452,  9515,  9546,  9615,\n",
      "        9690,  9757,  9820,  9915,  9978, 10055, 10130, 10217, 10304,\n",
      "       10393, 10484, 10545, 10620, 10711, 10784, 10859, 10916, 11003,\n",
      "       11060, 11103, 11170, 11259, 11322, 11409, 11478, 11527, 11610,\n",
      "       11653, 11718, 11779, 11850, 11905, 11948, 12013, 12080, 12137,\n",
      "       12180, 12251, 12322, 12389, 12462, 12563, 12650, 12719, 12790,\n",
      "       12853, 12924, 13003, 13074, 13147, 13224, 13287, 13332, 13387,\n",
      "       13454, 13503, 13572, 13615, 13666, 13703, 13782, 13855, 13936,\n",
      "       13997, 14064, 14127, 14204, 14281, 14380, 14437, 14494, 14547,\n",
      "       14634, 14703, 14764, 14831, 14878, 14983, 15038, 15121, 15180,\n",
      "       15255, 15328, 15403, 15476, 15523, 15582, 15651, 15702, 15767,\n",
      "       15822, 15891, 15936, 15997, 16092, 16177, 16248, 16323, 16416,\n",
      "       16475, 16576, 16625, 16680, 16769, 16878, 16933, 16994, 17025,\n",
      "       17082, 17135, 17200, 17241, 17346, 17419, 17474, 17529, 17598,\n",
      "       17655, 17732, 17801, 17842, 17905, 17956, 18017, 18058, 18127,\n",
      "       18186, 18259, 18352, 18435, 18498, 18537, 18614, 18653, 18748,\n",
      "       18813, 18870, 18925, 18984, 19065, 19158, 19229, 19300, 19383,\n",
      "       19454, 19495, 19560, 19629, 19696, 19783, 19850, 19911, 19972,\n",
      "       20023, 20064, 20109, 20208, 20265, 20356, 20403, 20464, 20551,\n",
      "       20620, 20669, 20724, 20819, 20892, 20957, 21008, 21035, 21096,\n",
      "       21175, 21244, 21337, 21388, 21421, 21518, 21563, 21644, 21701,\n",
      "       21792, 21861, 21936, 21981, 22068, 22109, 22180, 22253, 22338,\n",
      "       22405, 22448, 22523, 22582, 22655, 22720, 22805, 22882, 22959,\n",
      "       23020, 23057, 23112, 23191, 23262, 23333, 23412, 23475, 23550,\n",
      "       23633, 23688, 23741, 23812, 23859, 23920, 23993, 24072, 24137,\n",
      "       24222, 24293, 24364, 24447, 24522, 24585, 24678, 24739, 24800,\n",
      "       24841, 24914, 24993, 25084, 25149, 25220, 25259, 25306, 25397,\n",
      "       25464, 25523, 25600, 25643, 25708, 25777, 25842, 25899, 25954,\n",
      "       26043, 26080, 26171, 26230, 26295, 26346, 26441, 26506, 26555,\n",
      "       26624, 26701, 26762, 26795, 26842, 26927, 26978, 27055, 27120,\n",
      "       27191, 27260, 27311, 27370, 27467, 27542, 27575, 27650, 27705,\n",
      "       27806, 27849, 27896, 27957, 28044, 28123, 28202, 28287, 28350,\n",
      "       28423, 28480, 28531, 28586, 28669, 28748, 28791, 28874, 28931,\n",
      "       28992, 29059, 29174, 29251, 29326, 29387, 29450, 29529, 29624,\n",
      "       29673, 29742, 29793, 29836, 29901, 29954, 30019, 30076, 30131,\n",
      "       30192, 30221, 30300, 30357, 30432, 30497, 30588, 30663, 30722,\n",
      "       30775, 30806, 30873, 30926, 30999, 31044, 31101, 31168, 31229,\n",
      "       31298, 31369, 31430, 31503, 31564, 31645, 31732, 31793, 31872,\n",
      "       31917, 31976, 32069, 32132, 32187, 32260, 32307, 32382, 32443,\n",
      "       32474, 32539, 32588, 32665, 32722, 32821, 32872, 32955, 33040,\n",
      "       33099, 33166, 33213, 33262, 33323, 33384], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(Random_Forest.decision_path(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1fb59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c689101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd9a530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2946a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495bf3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
